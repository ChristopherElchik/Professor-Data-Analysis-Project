@article{10.1371/journal.pone.0210236:sourceB,
    doi = {10.1371/journal.pone.0210236},
    author = {Rodriguez, Mayra Z. AND Comin, Cesar H. AND Casanova, Dalcimar AND Bruno, Odemir M. AND Amancio, Diego R. AND Costa, Luciano da F. AND Rodrigues, Francisco A.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Clustering algorithms: A comparative approach},
    year = {2019},
    month = {01},
    volume = {14},
    url = {https://doi.org/10.1371/journal.pone.0210236},
    pages = {1-34},
    abstract = {Many real-world systems can be studied in terms of pattern recognition tasks, so that proper use (and understanding) of machine learning methods in practical applications becomes essential. While many classification methods have been proposed, there is no consensus on which methods are more suitable for a given dataset. As a consequence, it is important to comprehensively compare methods in many possible scenarios. In this context, we performed a systematic comparison of 9 well-known clustering methods available in the R language assuming normally distributed data. In order to account for the many possible variations of data, we considered artificial datasets with several tunable properties (number of classes, separation between classes, etc). In addition, we also evaluated the sensitivity of the clustering methods with regard to their parameters configuration. The results revealed that, when considering the default configurations of the adopted methods, the spectral approach tended to present particularly good performance. We also found that the default configuration of the adopted implementations was not always accurate. In these cases, a simple approach based on random selection of parameters values proved to be a good alternative to improve the performance. All in all, the reported approach provides subsidies guiding the choice of clustering algorithms.},
    number = {1},

}

@article{Abbas2005:sourceA,
  author    = {O. A. Abbas},
  title     = {Comparisons Between Data Clustering Algorithms},
  journal   = {International Arab Journal of Information Technology},
  year      = {2005},
  volume    = {5},
  number    = {3},
  pages     = {15-191},
  url       = {https://iajit.org/portal/PDF/vol.5,no.3/15-191.pdf},
}

@article{Xu2015:sourceC,
  author    = {Dongkuan Xu and Yingjie Tian},
  title     = {A Comprehensive Survey of Clustering Algorithms},
  journal   = {Annals of Data Science},
  year      = {2015},
  volume    = {2},
  number    = {2},
  pages     = {165-193},
  doi       = {10.1007/s40745-015-0040-1},
  url       = {https://doi.org/10.1007/s40745-015-0040-1},
  issn      = {2198-5812},
  abstract  = {Data analysis is used as a common method in modern science research, which is across communication science, computer science and biology science. Clustering, as the basic composition of data analysis, plays a significant role. On one hand, many tools for cluster analysis have been created, along with the information increase and subject intersection. On the other hand, each clustering algorithm has its own strengths and weaknesses, due to the complexity of information. In this review paper, we begin at the definition of clustering, take the basic elements involved in the clustering process, such as the distance or similarity measurement and evaluation indicators, into consideration, and analyze the clustering algorithms from two perspectives, the traditional ones and the modern ones. All the discussed clustering algorithms will be compared in detail and comprehensively shown in Appendix Table 22.},
}

@ARTICLE{10.3389/feduc.2022.842640:sourceD,

AUTHOR={Nushi, Musa  and Momeni, Ali  and Roshanbin, Maryam },

TITLE={Characteristics of an Effective University Professor From Students’ Perspective: Are the Qualities Changing?},

JOURNAL={Frontiers in Education},

VOLUME={7},

YEAR={2022},

URL={https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2022.842640},

DOI={10.3389/feduc.2022.842640},

ISSN={2504-284X},

ABSTRACT={<p>This study investigates the characteristics of an effective university professor based on the evaluations made by students in different majors at a state university in Iran. Two-hundred forty BA, MA, and Ph.D. students’ evaluations of their teachers were selected via purposive sampling. The evaluations were then content analyzed to determine which characteristics build the profile of an effective teacher in the students’ eyes. The results confirmed the findings of many previous studies that a good university professor needs to possess certain essential qualities. However, the profile of an effective university professor, at least the importance of the qualities that make up this profile, was rather different. More specifically, the most important criterion for evaluating the teachers was their assessment policies and practices. Furthermore, the findings suggest that the characteristics of an effective professor are dynamic and open to contextual, cultural and temporal influences. In light of the results of this study, it is recommended that higher education institutions put in place programs that educate teachers about a more learner-centered pedagogy to maximize not only their own teaching efficacy but also their students’ motivation and learning.</p>}
}

@article{LINSE201794:sourceE,
title = {Interpreting and using student ratings data: Guidance for faculty serving as administrators and on evaluation committees},
journal = {Studies in Educational Evaluation},
volume = {54},
pages = {94-106},
year = {2017},
note = {Evaluation of teaching: Challenges and promises},
issn = {0191-491X},
doi = {https://doi.org/10.1016/j.stueduc.2016.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0191491X16300232},
author = {Angela R. Linse},
keywords = {Faculty evaluation, Student ratings, Personnel evaluation, Evaluation usage, Evaluators},
abstract = {This article is about the accurate interpretation of student ratings data and the appropriate use of that data to evaluate faculty. Its aim is to make recommendations for use and interpretation based on more than 80 years of student ratings research. As more colleges and universities use student ratings data to guide personnel decisions, it is critical that administrators and faculty evaluators have access to research-based information about their use and interpretation. The article begins with an overview of common views and misconceptions about student ratings, followed by clarification of what student ratings are and are not. Next are two sections that provide advice for two audiences—administrators and faculty evaluators—to help them accurately, responsibly, and appropriately use and interpret student ratings data. A list of administrator questions is followed by a list of advice for faculty responsible for evaluating other faculty members’ records.}
}